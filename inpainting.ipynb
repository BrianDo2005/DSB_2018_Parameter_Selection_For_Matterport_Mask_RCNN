{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inpainting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mpsampat/DSB_2018_Parameter_Selection_For_Matterport_Mask_RCNN/blob/master/inpainting.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Wh_3HwwTFSl9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Code for **\"Inpainting\"** figures $6$, $8$ and 7 (top) from the main paper. \n",
        "\n",
        "See the website: https://dmitryulyanov.github.io/deep_image_prior"
      ]
    },
    {
      "metadata": {
        "id": "YdXH3bBBFVhN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Colaboratory Setup\n",
        "\n",
        "For **Colaboratory,** we need to install (updated) Pillow, torch, and also ensure that python can see our local-to-the-repo submodules. We will add a global variable `REPO_ROOT` which points to the repo (used later for image I/O)"
      ]
    },
    {
      "metadata": {
        "id": "Ue9erQPwFdGr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir -I pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHWaIPOrFdP2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmM6ApiZFjkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5rgLP1qGmE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!if [ -e deep-image-prior ]; then echo Repo already present; else git clone https://github.com/DmitryUlyanov/deep-image-prior.git; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P_S86aBOHDH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "REPO_ROOT = os.path.join(os.getcwd(), 'deep-image-prior')\n",
        "sys.path.append(REPO_ROOT)\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jyE1Wa8YHRso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "extra PIL workaround"
      ]
    },
    {
      "metadata": {
        "id": "gvN1OYxUHUU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "\n",
        "def register_extension(id, extension):\n",
        "    PIL.Image.EXTENSION[extension.lower()] = id.upper()\n",
        "PIL.Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions):\n",
        "    for extension in extensions:\n",
        "        register_extension(id, extension)\n",
        "PIL.Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSxXclixFSl-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import libs"
      ]
    },
    {
      "metadata": {
        "id": "95hXOVd2FSl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "import numpy as np\n",
        "from models.resnet import ResNet\n",
        "from models.unet import UNet\n",
        "from models.skip import skip\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from utils.inpainting_utils import *\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "PLOT = True\n",
        "imsize=-1\n",
        "dim_div_by = 64\n",
        "dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JL6ZwJeFSmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Choose figure"
      ]
    },
    {
      "metadata": {
        "id": "Jy7PQ6DoFSmD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Fig 6\n",
        "# img_path  = 'data/inpainting/vase.png'\n",
        "# mask_path = 'data/inpainting/vase_mask.png'\n",
        "\n",
        "## Fig 8\n",
        "# img_path  = 'data/inpainting/library.png'\n",
        "# mask_path = 'data/inpainting/library_mask.png'\n",
        "\n",
        "## Fig 7 (top)\n",
        "img_path  = 'data/inpainting/kate.png'\n",
        "mask_path = 'data/inpainting/kate_mask.png'\n",
        "\n",
        "\n",
        "NET_TYPE = 'skip_depth6' # one of skip_depth4|skip_depth2|UNET|ResNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PGvodLCTFSmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load mask"
      ]
    },
    {
      "metadata": {
        "id": "PTZAoHnBFSmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_pil, img_np = get_image(os.path.join(REPO_ROOT,img_path), imsize)\n",
        "img_mask_pil, img_mask_np = get_image(os.path.join(REPO_ROOT,mask_path), imsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-q4XqLBFSmM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Center crop"
      ]
    },
    {
      "metadata": {
        "id": "bhfhdBD1FSmO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_mask_pil = crop_image(img_mask_pil, dim_div_by)\n",
        "img_pil      = crop_image(img_pil,      dim_div_by)\n",
        "\n",
        "img_np      = pil_to_np(img_pil)\n",
        "img_mask_np = pil_to_np(img_mask_pil)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lRBklOnmFSmQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize"
      ]
    },
    {
      "metadata": {
        "id": "YT5iCXyuFSmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_mask_var = np_to_var(img_mask_np).type(dtype)\n",
        "\n",
        "plot_image_grid([img_np, img_mask_np, img_mask_np*img_np], 3,11);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mk2dj56jFSmX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "4Dwd3FoyFSmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pad = 'reflection' # 'zero'\n",
        "OPT_OVER = 'net'\n",
        "OPTIMIZER = 'adam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8rQXvaGYFSma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if 'vase.png' in img_path:\n",
        "    INPUT = 'meshgrid'\n",
        "    input_depth = 2\n",
        "    LR = 0.01 \n",
        "    num_iter = 5001\n",
        "    param_noise = False\n",
        "    show_every = 50\n",
        "    figsize = 5\n",
        "    reg_noise_std = 0.03\n",
        "    \n",
        "    net = skip(input_depth, img_np.shape[0], \n",
        "               num_channels_down = [128] * 5,\n",
        "               num_channels_up   = [128] * 5,\n",
        "               num_channels_skip = [0] * 5,  \n",
        "               upsample_mode='nearest', filter_skip_size=1, filter_size_up=3, filter_size_down=3,\n",
        "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "    \n",
        "elif 'kate.png' in img_path:\n",
        "    # Same params and net as in super-resolution and denoising\n",
        "    INPUT = 'noise'\n",
        "    input_depth = 32\n",
        "    LR = 0.01 \n",
        "    num_iter = 6001\n",
        "    param_noise = False\n",
        "    show_every = 50\n",
        "    figsize = 5\n",
        "    reg_noise_std = 0.03\n",
        "    \n",
        "    net = skip(input_depth, img_np.shape[0], \n",
        "               num_channels_down = [128] * 5,\n",
        "               num_channels_up =   [128] * 5,\n",
        "               num_channels_skip =    [4] * 5,  \n",
        "               filter_size_up = 3, filter_size_down = 3, \n",
        "               upsample_mode='nearest', filter_skip_size=1,\n",
        "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "    \n",
        "elif 'library.png' in img_path:\n",
        "    \n",
        "    INPUT = 'noise'\n",
        "    input_depth = 1\n",
        "    \n",
        "    num_iter = 3001\n",
        "    show_every = 50\n",
        "    figsize = 8\n",
        "    reg_noise_std = 0.00\n",
        "    param_noise = True\n",
        "    \n",
        "    if 'skip' in NET_TYPE:\n",
        "        \n",
        "        depth = int(NET_TYPE[-1])\n",
        "        net = skip(input_depth, img_np.shape[0], \n",
        "               num_channels_down = [16, 32, 64, 128, 128, 128][:depth],\n",
        "               num_channels_up =   [16, 32, 64, 128, 128, 128][:depth],\n",
        "               num_channels_skip =    [0, 0, 0, 0, 0, 0][:depth],  \n",
        "               filter_size_up = 3,filter_size_down = 5,  filter_skip_size=1,\n",
        "               upsample_mode='nearest', # downsample_mode='avg',\n",
        "               need1x1_up=False,\n",
        "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "        \n",
        "        LR = 0.01 \n",
        "        \n",
        "    elif NET_TYPE == 'UNET':\n",
        "        \n",
        "        net = UNet(num_input_channels=input_depth, num_output_channels=3, \n",
        "                   feature_scale=8, more_layers=1, \n",
        "                   concat_x=False, upsample_mode='deconv', \n",
        "                   pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n",
        "        \n",
        "        LR = 0.001\n",
        "        param_noise = False\n",
        "        \n",
        "    elif NET_TYPE == 'ResNet':\n",
        "        \n",
        "        net = ResNet(input_depth, img_np.shape[0], 8, 32, need_sigmoid=True, act_fun='LeakyReLU')\n",
        "        \n",
        "        LR = 0.001\n",
        "        param_noise = False\n",
        "        \n",
        "    else:\n",
        "        assert False\n",
        "else:\n",
        "    assert False\n",
        "\n",
        "net = net.type(dtype)\n",
        "net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePQdyQ12FSmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute number of parameters\n",
        "s  = sum(np.prod(list(p.size())) for p in net.parameters())\n",
        "print ('Number of params: %d' % s)\n",
        "\n",
        "# Loss\n",
        "mse = torch.nn.MSELoss().type(dtype)\n",
        "\n",
        "img_var = np_to_var(img_np).type(dtype)\n",
        "mask_var = np_to_var(img_mask_np).type(dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zcq_DH-_FSmi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Main loop"
      ]
    },
    {
      "metadata": {
        "id": "8jyJSRsVFUVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "def closure():\n",
        "    \n",
        "    global i\n",
        "    \n",
        "    if param_noise:\n",
        "        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
        "            n.data += n.data.clone().normal_()*n.data.std()/50\n",
        "    \n",
        "    if reg_noise_std > 0:\n",
        "        net_input.data = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "        \n",
        "        \n",
        "    out = net(net_input)\n",
        "   \n",
        "    total_loss = mse(out * mask_var, img_var * mask_var)\n",
        "    total_loss.backward()\n",
        "        \n",
        "    print ('Iteration %05d    Loss %f' % (i, total_loss.data[0]), '\\r', end='')\n",
        "    if  PLOT and i % show_every == 0:\n",
        "        out_np = var_to_np(out)\n",
        "        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)\n",
        "        \n",
        "    i += 1\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "net_input_saved = net_input.data.clone()\n",
        "noise = net_input.data.clone()\n",
        "p = get_params(OPT_OVER, net, net_input)\n",
        "beginTime = time.time()\n",
        "optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
        "elapsedTime = time.time() - beginTime\n",
        "print(\"Calculations complete after {:2g} seconds\".format(elapsedTime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XPG8XszFUVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_np = var_to_np(net(net_input))\n",
        "plot_image_grid([out_np], factor=5);"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}